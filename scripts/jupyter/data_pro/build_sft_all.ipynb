{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build SFT data of all labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "os.environ['HF_HUB_CACHE'] = '/next_share/hf_cache/hub/'\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, PreTrainedTokenizer\n",
    "import importlib\n",
    "import numpy as np\n",
    "import difflib\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "import context\n",
    "os.chdir(context.proj_dir)\n",
    "\n",
    "import cont_gen\n",
    "import cont_gen.data_process.ood.build_src_tgt\n",
    "import cont_gen.data_process.ood.build_sft_meta_data\n",
    "importlib.reload(cont_gen.data_process.ood.build_src_tgt)\n",
    "importlib.reload(cont_gen.data_process.ood.build_sft_meta_data)\n",
    "from cont_gen.data_process.ood.build_src_tgt import process, SFT_Builder, SFT_Builder_YesNo, SFT_Builder_YesNo_Natural\n",
    "from cont_gen.data_process.ood.build_sft_meta_data import CUAD_Basic, MetaSFT_Train_Builder, MetaSFT_Test_Builder\n",
    "from cont_gen.data_loader.cuad_sft import CUAD_SFT_Cached\n",
    "from cont_gen.utils import load_jsonl, save_jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def build_train_meta(train_para_data, train_labels, output_dir, neg_clause_ratio=1.0, num_neg_quest = 1):\n",
    "    \"\"\"Build and save train meta data.\"\"\"\n",
    "    all_df = MetaSFT_Train_Builder.build_pos_neg_samples(\n",
    "        train_para_data,\n",
    "        train_labels,\n",
    "        neg_clause_ratio=neg_clause_ratio,\n",
    "        num_neg_quest=num_neg_quest)\n",
    "\n",
    "    Path(output_dir).mkdir(parents = True, exist_ok=True)\n",
    "    all_df.to_csv(Path(output_dir) / 'train_meta.csv', index = False)\n",
    "\n",
    "    return all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handle tokenizer data: flan-t5\n",
      "Handle tokenizer data: llama3\n",
      "Handle tokenizer data: mistral\n"
     ]
    }
   ],
   "source": [
    "tkn_names = ['flan-t5', 'llama3', 'mistral']\n",
    "\n",
    "train_labels = list(range(41))\n",
    "\n",
    "for tkn_name in tkn_names:\n",
    "    print(f'Handle tokenizer data: {tkn_name}')\n",
    "    train_para_data = load_jsonl(f'data/cuad_clean/merge_split/paras_{tkn_name}_512.jsonl')\n",
    "    build_train_meta(train_para_data, train_labels, f'data/cuad_sft/{tkn_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process data/cuad_sft\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26455/26455 [00:00<00:00, 67915.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process data/cuad_sft\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26309/26309 [00:00<00:00, 68857.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process data/cuad_sft\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26569/26569 [00:00<00:00, 69741.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# Add template\n",
    "from ast import literal_eval\n",
    "def process_sft_tokenizer(tkn_name, output_dir, builder: SFT_Builder, pmt_name):\n",
    "    \"\"\"Build meta data for one tokenizer under multiple splits\"\"\"\n",
    "    all_para_data = load_jsonl(f'data/cuad_clean/merge_split/paras_{tkn_name}_512.jsonl')\n",
    "    builder.set_para_data(all_para_data)\n",
    "\n",
    "    \n",
    "    print(f'Process {output_dir}')\n",
    "    meta_dir = Path(output_dir) / tkn_name # data for one tokenizer\n",
    "    save_dir = meta_dir / pmt_name\n",
    "    train_meta = pd.read_csv(meta_dir / 'train_meta.csv', converters={'answers': literal_eval})\n",
    "    train_data  = process(builder, train_meta)\n",
    "    save_jsonl(train_data, save_dir / 'train_data.jsonl')\n",
    "\n",
    "clause_info = pd.read_csv('./data/clause/all_info.csv')\n",
    "prompt_01 = open('config/prompts/pmt_01.txt', 'r').read()\n",
    "builder = SFT_Builder(prompt_01, clause_info, None, lambda k: k)\n",
    "\n",
    "for tkn_name in tkn_names:\n",
    "    process_sft_tokenizer(tkn_name, 'data/cuad_sft', builder, 'pmt_01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
