{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2,3'\n",
    "os.environ['HF_HUB_CACHE'] = '/next_share/hf_cache/hub'\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from transformers import AutoTokenizer, BitsAndBytesConfig, AutoModelForCausalLM, LlamaForCausalLM, PreTrainedModel, AutoModelForSeq2SeqLM\n",
    "from peft import get_peft_model, LoraConfig, get_peft_model_state_dict, AutoPeftModelForCausalLM, load_peft_weights\n",
    "import importlib\n",
    "import difflib\n",
    "from collections import defaultdict\n",
    "\n",
    "import context\n",
    "os.chdir(context.proj_dir)\n",
    "\n",
    "import cont_gen\n",
    "import cont_gen.data_process.pre_process.split_long_para\n",
    "import cont_gen.utils.model_utils\n",
    "_ = importlib.reload(cont_gen.data_process.pre_process.split_long_para)\n",
    "importlib.reload(cont_gen.utils.model_utils)\n",
    "from cont_gen.data_loader.cuad_sft import CUAD_SFT_Cached\n",
    "from cont_gen.utils.model_utils import load_hf_model_from_checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "1. [Link](#model-initialize) Explore model initialize.\n",
    "   1. Q-lora\n",
    "   2. Device map\n",
    "   3. Show dataset\n",
    "   4. [Link](#lora-demo) Lora demo\n",
    "2. [Link](#explore-memory-usage) Explore the memory usage\n",
    "3. [Link](#gradient-checkpointing) Explore gradient checkpointing\n",
    "4. Explore how to adapt to chat model, e.g., llama2-chat and llama3-instruct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device_map(model_name):\n",
    "    if torch.cuda.device_count() == 2:\n",
    "        if any([k in model_name for k in ['llama', 'mistral']]):\n",
    "            device_map = {\n",
    "                'model.embed_tokens': 0,\n",
    "                'model.norm': 1,\n",
    "                'lm_head': 1\n",
    "            }\n",
    "            device_map.update({f'model.layers.{i}': 0 if i < 16 else 1 for i in range(32)})\n",
    "        else:\n",
    "            device_map = 'auto'\n",
    "    elif torch.cuda.device_count() == 1:\n",
    "        device_map = {\"\":0}\n",
    "    else:\n",
    "        device_map = 'auto'\n",
    "    return device_map\n",
    "\n",
    "model_names = {'llama3': 'meta-llama/Meta-Llama-3-8B',\n",
    "               'mistral': 'mistralai/Mistral-7B-v0.1',\n",
    "               'llama2': 'meta-llama/Llama-2-7b-hf',\n",
    "               'flan-t5-xl': 'google/flan-t5-xl'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2e89f38d801407a9f814d0cf3027702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This quantization config is for QLora\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "model_name = model_names['llama3']\n",
    "# model_name = 'bert-base-uncased'\n",
    "mod_cls = AutoModelForSeq2SeqLM if 't5' in model_name else AutoModelForCausalLM\n",
    "model = mod_cls.from_pretrained(\n",
    "    model_name,\n",
    "    cache_dir = '/next_share/hf_cache/hub',\n",
    "    device_map = get_device_map(model_name),\n",
    "    torch_dtype = torch.bfloat16,\n",
    "    # quantization_config = quant_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Device Map\n",
    "\n",
    "**Mistral**:\n",
    "- modules (GB):\n",
    "  - 'model.embed_tokens': 0.1311\n",
    "  - 'model.layers.{0..31}': 0.2181\n",
    "  - 'model.norm': 0\n",
    "  - 'lm_head': 0.1311\n",
    "- Tie: False\n",
    "- Device map:\n",
    "  - emb: 0\n",
    "  - layers 0-15: 0\n",
    "  - layers 16-31: 1\n",
    "  - norm, lm_head: 1\n",
    "\n",
    "**LLaMA 3**:\n",
    "- modules:\n",
    "  - 'model.embed_tokens': 0.5253\n",
    "  - 'model.layers.{0..31}': 0.2181\n",
    "  - 'model.norm': 0\n",
    "  - 'lm_head': 0.5253\n",
    "- Tie: False\n",
    "- Device map:\n",
    "  - emb: 0\n",
    "  - layers 0-13: 0\n",
    "  - layers 14-31: 1\n",
    "  - norm, lm_head: 1\n",
    "- Difference: 4 layers, 0.88B, 1.8GB, Real: 7777 vs 9457 MB\n",
    "\n",
    "**LLaMA2**:\n",
    "- modules:\n",
    "  - 'model.embed_tokens': 0.1311\n",
    "  - 'model.layers.{0..31}': 0.2024\n",
    "- Device map: same as mistral. layers are equally divided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.hf_device_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_el(mod, exp = 3):\n",
    "    \"\"\"get number of parameters. exp=3 means returning in Billion\"\"\"\n",
    "    tot_p = sum(p.numel() for p in mod.parameters())\n",
    "    # print(tot_p)\n",
    "    return tot_p / (1000**exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.849757184\n"
     ]
    }
   ],
   "source": [
    "print(num_el(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.1311', '0.2024', '0.0000', '0.1311']\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Print the parameter number of sub modules\n",
    "n2mod = {k:v for k,v in model.named_modules()}\n",
    "np_emb = num_el(n2mod['model.embed_tokens'])\n",
    "np_layer = num_el(n2mod['model.layers.0'])\n",
    "np_norm = num_el(n2mod['model.norm'])\n",
    "np_head = num_el(n2mod['lm_head'])\n",
    "print([f'{k:.4f}' for k in [np_emb, np_layer, np_norm, np_head]])\n",
    "print(model.get_output_embeddings() is model.get_input_embeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.73841152\n",
      "6.738415616\n"
     ]
    }
   ],
   "source": [
    "# Validate total parameter number\n",
    "tot_add = np_emb + np_layer * 32 + np_head\n",
    "print(tot_add)\n",
    "print(num_el(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lora Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 41,943,040 || all params: 8,072,204,288 || trainable%: 0.5195983464188562\n"
     ]
    }
   ],
   "source": [
    "peft_config = LoraConfig(\n",
    "    r = 16, lora_alpha = 16,\n",
    "    # target_modules = None,\n",
    "    target_modules = 'all-linear',\n",
    "    lora_dropout= 0.1,\n",
    "    bias = \"none\"\n",
    ")\n",
    "\n",
    "lora_model = get_peft_model(model, peft_config)\n",
    "lora_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lora_model.save_pretrained('runs/debug/lora_ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tk_mistral = AutoTokenizer.from_pretrained(model_names['mistral'], cache_dir = '/next_share/hf_cache/hub')\n",
    "tk_llama3 = AutoTokenizer.from_pretrained(model_names['llama3'], cache_dir = '/next_share/hf_cache/hub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load from cache: data/ood_split/seed128_tr29/mistral/pmt_01_yes_no/cache/cached_train_data.jsonl_Mistral-7B-v0.1_v1.0.pkl\n"
     ]
    }
   ],
   "source": [
    "data_path = 'data/ood_split/seed128_tr29/mistral/pmt_01_yes_no/train_data.jsonl'\n",
    "dataset = CUAD_SFT_Cached(\n",
    "    data_path,\n",
    "    tk_mistral,\n",
    "    is_seq2seq = False,\n",
    "    cache_dir = Path(data_path).parent / 'cache',\n",
    "    max_src_length = None,\n",
    "    max_tgt_length = None,\n",
    "    labels_on_full = False,\n",
    "    is_test = False,\n",
    "    small = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1117\n"
     ]
    }
   ],
   "source": [
    "ipt_lens = [len(k['input_ids']) for k in dataset]\n",
    "print(max(ipt_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_i = np.argmax(ipt_lens)\n",
    "d = dataset.data[max_i]\n",
    "# print(d['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[28723, 387, 12751, 4572, 23148, 1017, 14778, 8472, 7178, 2]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]['input_ids'][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk_mistral.unk_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Memory Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "911b309cece0425094069d4c15088231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c92582b16c145e4bea0d719651564f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67b9de2b3b2940c5b0a6a93389a4a3e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained('gpt2', cache_dir = '/next_share/hf_cache/hub').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynvml import *\n",
    "\n",
    "class NVML_Mem:\n",
    "    def __init__(self, gpu_indexes = None):\n",
    "        self.gpu_indexes = gpu_indexes if gpu_indexes is not None else \\\n",
    "                    [int(k) for k in os.environ['CUDA_VISIBLE_DEVICES'].split(',')]\n",
    "        nvmlInit()\n",
    "    \n",
    "    def __call__(self):\n",
    "        return [self.get_mem_by_id(k) for k in self.gpu_indexes]\n",
    "    \n",
    "    def get_mem_by_id(self, index):\n",
    "        h = nvmlDeviceGetHandleByIndex(index)\n",
    "        info = nvmlDeviceGetMemoryInfo(h)\n",
    "        return info.used / 1024**3\n",
    "    \n",
    "\n",
    "def get_mem_of_len(ipt_len, model, gpu_ids, optimizer):\n",
    "    \"\"\"Return Memory of all gpus in GiB\"\"\"\n",
    "    input_ids = torch.tensor([1]*ipt_len).cuda().unsqueeze(0)\n",
    "    optimizer.zero_grad()\n",
    "    loss = model(input_ids, labels = input_ids).loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return NVML_Mem(gpu_ids)()\n",
    "\n",
    "def get_infer_mem_of_len(ipt_len, model, gpu_ids):\n",
    "    \"\"\"Return Memory of all gpus in GiB\"\"\"\n",
    "    input_ids = torch.tensor([1]*ipt_len).cuda().unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        loss = model(input_ids, labels = input_ids).loss\n",
    "    \n",
    "    return NVML_Mem(gpu_ids)()\n",
    "\n",
    "def scan_mem(step, num_steps, model, gpu_ids):\n",
    "    optimizer = torch.optim.AdamW(model.parameters())\n",
    "    memorys = [NVML_Mem(gpu_ids)()]\n",
    "    for step_i in range(1, num_steps + 1):\n",
    "        memorys.append(get_mem_of_len(step * step_i, model, gpu_ids, optimizer))\n",
    "    return memorys\n",
    "\n",
    "def scan_mem_infer(step, num_steps, model, gpu_ids = None):\n",
    "    memorys = [NVML_Mem(gpu_ids)()]\n",
    "    for step_i in range(1, num_steps + 1):\n",
    "        memorys.append(get_infer_mem_of_len(step * step_i, model, gpu_ids))\n",
    "    return memorys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15.52020263671875, 15.65301513671875], [15.52020263671875, 15.65301513671875], [15.52020263671875, 15.65301513671875], [15.52020263671875, 15.65301513671875], [15.52020263671875, 15.65301513671875], [15.52020263671875, 15.65301513671875], [15.88739013671875, 15.65301513671875]]\n"
     ]
    }
   ],
   "source": [
    "lora_model.gradient_checkpointing_disable()\n",
    "n_steps = 6\n",
    "memory_list = scan_mem(128, n_steps, model, [int(k) for k in os.environ['CUDA_VISIBLE_DEVICES'].split(',')])\n",
    "print(memory_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_model.enable_input_require_grads()\n",
    "lora_model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for k,v in lora_model.named_modules():\n",
    "    if hasattr(v, \"gradient_checkpointing\"):\n",
    "        res.append((v, v.gradient_checkpointing))\n",
    "print(len(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.46356201171875, 8.46356201171875], [9.55535888671875, 9.73114013671875], [10.45965576171875, 10.76824951171875], [11.42840576171875, 11.89520263671875], [12.36395263671875, 12.97528076171875], [13.53387451171875, 14.24481201171875], [15.55340576171875, 15.65301513671875]]\n"
     ]
    }
   ],
   "source": [
    "# Memory for Gradient Checkpointing\n",
    "\n",
    "n_steps = 6\n",
    "memory_list = scan_mem(128, n_steps, lora_model, [int(k) for k in os.environ['CUDA_VISIBLE_DEVICES'].split(',')])\n",
    "print(memory_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9.04168701171875, 8.99871826171875]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NVML_Mem()()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f06ac33fd30>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.arange(n_steps + 1)\n",
    "mems = np.array(memory_list)\n",
    "for col in range(mems.shape[1]):\n",
    "    plt.plot(x, mems[:,col], color = f'C{col}', label = f'GPU {col}')\n",
    "# plt.plot(x, mems[:,1], color = 'g')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3583984375\n"
     ]
    }
   ],
   "source": [
    "k = (mems[-1,0] - mems[0, 0]) / n_steps\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73828125 0.8515625  0.95117188 0.84765625 1.23242188 2.13867188\n",
      " 1.734375   2.37304688]\n"
     ]
    }
   ],
   "source": [
    "incre = mems[1:,0] - mems[:-1,0]\n",
    "print(incre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15.709716796875], [15.947998046875], [16.199951171875], [16.600341796875], [17.092529296875], [17.705810546875], [18.440185546875], [19.297607421875], [20.278076171875]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# inference mem\n",
    "n_steps = 8\n",
    "infer_memory_list = scan_mem_infer(128, n_steps, model, [int(k) for k in os.environ['CUDA_VISIBLE_DEVICES'].split(',')])\n",
    "print(infer_memory_list)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.arange(n_steps + 1)\n",
    "mems = np.array(infer_memory_list)\n",
    "for col in range(mems.shape[1]):\n",
    "    plt.plot(x, mems[:,col], color = f'C{col}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:-1 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "r = model.generate(input_ids = torch.tensor([1]*512).cuda().unsqueeze(0),max_new_tokens = 512, eos_token_id = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\" ( =>000 (r\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\def\\\\'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk_llama3.batch_decode(r)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(r[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, steps, input_len = 1024):\n",
    "    input_ids = torch.tensor([1]*input_len).cuda().unsqueeze(0)\n",
    "    optimizer = torch.optim.AdamW(model.parameters())\n",
    "    for _ in tqdm(list(range(steps))):\n",
    "        optimizer.zero_grad()\n",
    "        loss = model(input_ids, labels = input_ids).loss\n",
    "        loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.129638671875, 8.129638671875]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20/20 [00:16<00:00,  1.18it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[17.697998046875, 19.094482421875]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(NVML_Mem()())\n",
    "lora_model.gradient_checkpointing_enable()\n",
    "train_loop(model, 20, input_len = 1122)\n",
    "NVML_Mem()()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20/20 [00:19<00:00,  1.01it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 112.00 MiB (GPU 0; 22.19 GiB total capacity; 20.73 GiB already allocated; 77.31 MiB free; 21.17 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/storage/rhshui/workspace/contract_review/scripts/jupyter/play_model.ipynb Cell 37\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bnext-asus-2/storage/rhshui/workspace/contract_review/scripts/jupyter/play_model.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39mgradient_checkpointing_disable()\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bnext-asus-2/storage/rhshui/workspace/contract_review/scripts/jupyter/play_model.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m train_loop(model, \u001b[39m20\u001b[39;49m, input_len \u001b[39m=\u001b[39;49m \u001b[39m1122\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bnext-asus-2/storage/rhshui/workspace/contract_review/scripts/jupyter/play_model.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m NVML_Mem()()\n",
      "\u001b[1;32m/storage/rhshui/workspace/contract_review/scripts/jupyter/play_model.ipynb Cell 37\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bnext-asus-2/storage/rhshui/workspace/contract_review/scripts/jupyter/play_model.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     loss \u001b[39m=\u001b[39m model(input_ids, labels \u001b[39m=\u001b[39m input_ids)\u001b[39m.\u001b[39mloss\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bnext-asus-2/storage/rhshui/workspace/contract_review/scripts/jupyter/play_model.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bnext-asus-2/storage/rhshui/workspace/contract_review/scripts/jupyter/play_model.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep()\n",
      "File \u001b[0;32m/storage_fast/rhshui/lib/anaconda3/envs/llm/lib/python3.9/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/storage_fast/rhshui/lib/anaconda3/envs/llm/lib/python3.9/site-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     34\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m/storage_fast/rhshui/lib/anaconda3/envs/llm/lib/python3.9/site-packages/torch/optim/adamw.py:160\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    157\u001b[0m     amsgrad \u001b[39m=\u001b[39m group[\u001b[39m\"\u001b[39m\u001b[39mamsgrad\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    158\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m\"\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m--> 160\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_group(\n\u001b[1;32m    161\u001b[0m         group,\n\u001b[1;32m    162\u001b[0m         params_with_grad,\n\u001b[1;32m    163\u001b[0m         grads,\n\u001b[1;32m    164\u001b[0m         amsgrad,\n\u001b[1;32m    165\u001b[0m         exp_avgs,\n\u001b[1;32m    166\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    167\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    168\u001b[0m         state_steps,\n\u001b[1;32m    169\u001b[0m     )\n\u001b[1;32m    171\u001b[0m     adamw(\n\u001b[1;32m    172\u001b[0m         params_with_grad,\n\u001b[1;32m    173\u001b[0m         grads,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    190\u001b[0m         found_inf\u001b[39m=\u001b[39m\u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfound_inf\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[1;32m    191\u001b[0m     )\n\u001b[1;32m    193\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/storage_fast/rhshui/lib/anaconda3/envs/llm/lib/python3.9/site-packages/torch/optim/adamw.py:118\u001b[0m, in \u001b[0;36mAdamW._init_group\u001b[0;34m(self, group, params_with_grad, grads, amsgrad, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps)\u001b[0m\n\u001b[1;32m    114\u001b[0m state[\u001b[39m\"\u001b[39m\u001b[39mexp_avg\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros_like(\n\u001b[1;32m    115\u001b[0m     p, memory_format\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mpreserve_format\n\u001b[1;32m    116\u001b[0m )\n\u001b[1;32m    117\u001b[0m \u001b[39m# Exponential moving average of squared gradient values\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m state[\u001b[39m\"\u001b[39m\u001b[39mexp_avg_sq\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mzeros_like(\n\u001b[1;32m    119\u001b[0m     p, memory_format\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mpreserve_format\n\u001b[1;32m    120\u001b[0m )\n\u001b[1;32m    121\u001b[0m \u001b[39mif\u001b[39;00m amsgrad:\n\u001b[1;32m    122\u001b[0m     \u001b[39m# Maintains max of all exp. moving avg. of sq. grad. values\u001b[39;00m\n\u001b[1;32m    123\u001b[0m     state[\u001b[39m\"\u001b[39m\u001b[39mmax_exp_avg_sq\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros_like(\n\u001b[1;32m    124\u001b[0m         p, memory_format\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mpreserve_format\n\u001b[1;32m    125\u001b[0m     )\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 112.00 MiB (GPU 0; 22.19 GiB total capacity; 20.73 GiB already allocated; 77.31 MiB free; 21.17 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "model.gradient_checkpointing_disable()\n",
    "train_loop(model, 20, input_len = 1122)\n",
    "NVML_Mem()()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.30340576171875, 0.30340576171875]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "seq_len, dataset_size = 512, 16\n",
    "dummy_data = {\n",
    "    \"input_ids\": np.random.randint(100, 30000, (dataset_size, seq_len)),\n",
    "}\n",
    "dummy_data['labels'] = dummy_data['input_ids']\n",
    "ds = Dataset.from_dict(dummy_data)\n",
    "ds.set_format(\"pt\")\n",
    "\n",
    "print(NVML_Mem()())\n",
    "\n",
    "default_args = {\n",
    "    \"output_dir\": \"tmp\",\n",
    "    \"evaluation_strategy\": \"steps\",\n",
    "    \"num_train_epochs\": 1,\n",
    "    \"log_level\": \"error\",\n",
    "    \"report_to\": \"none\",\n",
    "    'remove_unused_columns': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_model.enable_input_require_grads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lora_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/storage/rhshui/workspace/contract_review/scripts/jupyter/play_model.ipynb Cell 45\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bnext-asus-2/storage/rhshui/workspace/contract_review/scripts/jupyter/play_model.ipynb#Y104sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m training_args \u001b[39m=\u001b[39m TrainingArguments(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bnext-asus-2/storage/rhshui/workspace/contract_review/scripts/jupyter/play_model.ipynb#Y104sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     per_device_train_batch_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bnext-asus-2/storage/rhshui/workspace/contract_review/scripts/jupyter/play_model.ipynb#Y104sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     gradient_checkpointing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bnext-asus-2/storage/rhshui/workspace/contract_review/scripts/jupyter/play_model.ipynb#Y104sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdefault_args\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bnext-asus-2/storage/rhshui/workspace/contract_review/scripts/jupyter/play_model.ipynb#Y104sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m )\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bnext-asus-2/storage/rhshui/workspace/contract_review/scripts/jupyter/play_model.ipynb#Y104sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(model\u001b[39m=\u001b[39mlora_model, args\u001b[39m=\u001b[39mtraining_args, train_dataset\u001b[39m=\u001b[39mds)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bnext-asus-2/storage/rhshui/workspace/contract_review/scripts/jupyter/play_model.ipynb#Y104sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# tr_dl = trainer.get_train_dataloader()\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bnext-asus-2/storage/rhshui/workspace/contract_review/scripts/jupyter/play_model.ipynb#Y104sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# result = trainer.train()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnext-asus-2/storage/rhshui/workspace/contract_review/scripts/jupyter/play_model.ipynb#Y104sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(NVML_Mem()())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lora_model' is not defined"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=1, \n",
    "    gradient_checkpointing=True,\n",
    "    **default_args\n",
    ")\n",
    "trainer = Trainer(model=lora_model, args=training_args, train_dataset=ds)\n",
    "\n",
    "# tr_dl = trainer.get_train_dataloader()\n",
    "# result = trainer.train()\n",
    "\n",
    "print(NVML_Mem()())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ParallelMode.NOT_DISTRIBUTED: 'not_distributed'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args.parallel_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.36.2'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load PEFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_id = 'runs/ood/llama3/seed42_tr29/pmt_01_all_lr1e-5_bs16_wd0.0/checkpoint-15692'\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     peft_id, \n",
    "#     cache_dir = '/next_share/hf_cache/hub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = torch.load(Path(peft_id) / 'adapter_model.bin', map_location = 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print([k for k in st.keys() if 'layer' not in k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "448"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16ec8611ea164c659775fcfae637537a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resize embedding num to 128257\n"
     ]
    }
   ],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "model = load_hf_model_from_checkpoint(peft_id, Accelerator(), 'bf16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "gen_r = model.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|begin_of_text|>Question:\\nWhat is the greatest common factor of 126 and 105?\\nAnswer:\\n21<|end_of_text|>'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk_llama3.batch_decode(gen_r)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|end_of_text|>\n",
      "128001\n",
      "128256\n"
     ]
    }
   ],
   "source": [
    "tk_llama3.pad_token = tk_llama3.eos_token\n",
    "print(tk_llama3.pad_token)\n",
    "print(tk_llama3.pad_token_id)\n",
    "print(len(tk_llama3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight\n",
      "torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "ipt_emb = model.get_input_embeddings()\n",
    "ipt_emb_n, ipt_emb_w = list(ipt_emb.named_parameters())[0]\n",
    "print(ipt_emb_n)\n",
    "print(ipt_emb_w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.wte\n"
     ]
    }
   ],
   "source": [
    "for n,m in model.named_modules():\n",
    "    if m is model.get_input_embeddings():\n",
    "        print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = load_peft_weights(peft_id)\n",
    "keys = list(st.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['base_model.model.model.embed_tokens.weight',\n",
       " 'base_model.model.lm_head.weight']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
